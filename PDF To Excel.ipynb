{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF To Export into Excel...\n",
    "*****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Appending rows in excel xlswriter Link](https://stackoverflow.com/questions/45103927/appending-rows-in-excel-xlswriter)\n",
    "\n",
    "[Extracting data from HTML table](https://stackoverflow.com/questions/11790535/extracting-data-from-html-table)\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://www.winnovative-software.com/img/logo.jpg\" />\n",
    "\n",
    "> PDF First convert into PDF To HTML [Winnovative Link](https://www.winnovative-software.com/pdf-to-html-converter.aspx)\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "Collecting jdcal (from openpyxl)\n",
      "  Using cached https://files.pythonhosted.org/packages/f0/da/572cbc0bc582390480bbd7c4e93d14dc46079778ed915b505dc494b37c57/jdcal-1.4.1-py2.py3-none-any.whl\n",
      "Installing collected packages: et-xmlfile, jdcal, openpyxl\n",
      "Successfully installed et-xmlfile-1.0.1 jdcal-1.4.1 openpyxl-3.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "filename = \"myfile.xlsx\"\n",
    "new_row = ['1', '2', '3']\n",
    "\n",
    "# Confirm file exists. \n",
    "# If not, create it, add headers, then append new data\n",
    "try:\n",
    "    wb = load_workbook(filename)\n",
    "    ws = wb.worksheets[0]  # select first worksheet\n",
    "except FileNotFoundError:\n",
    "    headers_row = ['Header 1', 'Header 2', 'Header 3']\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.append(headers_row)\n",
    "\n",
    "ws.append(new_row)\n",
    "wb.save(filename)\n",
    "\n",
    "# Note: if you're adding values from a list, you could instead use:\n",
    "# new_row = \"\"\n",
    "# new_row += [val for val in list]\n",
    "# Similarly, for adding values from a dict:\n",
    "# new_row = \"\"\n",
    "# new_row = += [val for val in mydict['mykey'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "print(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Extracting data from HTML table](https://stackoverflow.com/questions/11790535/extracting-data-from-html-table)\n",
    "\n",
    "We Can Extract Data from PDF to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "  <table class=\"details\" border=\"0\" cellpadding=\"5\" cellspacing=\"2\" width=\"95%\">\n",
    "    <tr valign=\"top\">\n",
    "      <th>Tests</th>\n",
    "      <th>Failures</th>\n",
    "      <th>Success Rate</th>\n",
    "      <th>Average Time</th>\n",
    "      <th>Min Time</th>\n",
    "      <th>Max Time</th>\n",
    "   </tr>\n",
    "   <tr valign=\"top\" class=\"Failure\">\n",
    "     <td>103</td>\n",
    "     <td>24</td>\n",
    "     <td>76.70%</td>\n",
    "     <td>71 ms</td>\n",
    "     <td>0 ms</td>\n",
    "     <td>829 ms</td>\n",
    "  </tr>\n",
    "</table>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "table = soup.find(\"table\", attrs={\"class\":\"details\"})\n",
    "\n",
    "# The first tr contains the field names.\n",
    "headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "\n",
    "datasets = []\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    dataset = zip(headings, (td.get_text() for td in row.find_all(\"td\")))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "for dataset in datasets:\n",
    "    for field in dataset:\n",
    "        print (\"{0:<16}: {1}\".format(field[0], field[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"/home/qmis/Jaimon/Jaimon/28282.pdf\"\n",
    "os.system('pdftohtml -s -xml -i -c -q %s %s' % (path, path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.easyxls.com/manual/tutorials/python/convert-xml-spreadsheet-to-excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'py4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d0cda83e191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_gateway\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJavaGateway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_gateway\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjava_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJavaGateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py4j'"
     ]
    }
   ],
   "source": [
    "\"\"\"------------------------------------------------------------------------\n",
    "Tutorial 41\n",
    "\n",
    "This tutorial shows how to convert XML spreadsheet to Excel in Python. The\n",
    "XML Spreadsheet generated by Tutorial 32 is imported, some data is modified\n",
    "and after that is exported as Excel file.\n",
    "------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "import gc\n",
    "\n",
    "from py4j.java_gateway import JavaGateway\n",
    "from py4j.java_gateway import java_import \n",
    "gateway = JavaGateway()\n",
    "\n",
    "java_import(gateway.jvm,'EasyXLS.*')\n",
    "\n",
    "print(\"Tutorial 41\\n-----------\\n\")\n",
    "\n",
    "# Create an instance of the class used to import/export Excel files\n",
    "workbook = gateway.jvm.ExcelDocument()\n",
    "\n",
    "# Import XML Spreadsheet file\n",
    "print(\"Reading file C:\\\\Samples\\\\Tutorial32.xml\")\n",
    "\t\t\n",
    "if workbook.easy_LoadXMLSpreadsheetFile(\"/home/qmis/Jaimon/Jaimon/28282.pdf.xml\"):\n",
    "    # Get the table of data from the second sheet and add some data in cells (optional step)\n",
    "    xlsSecondTable = workbook.easy_getSheet(\"Second tab\").easy_getExcelTable()\n",
    "    xlsSecondTable.easy_getCell(\"A1\").setValue(\"Data added by Tutorial41\")\n",
    "\t\t\t\t\t\t\n",
    "    for column in range(5):\n",
    "        xlsSecondTable.easy_getCell(1, column).setValue(\"Data \" + str(column + 1))\n",
    "\n",
    "    # Export Excel file\n",
    "    print(\"\\nWriting file C:\\\\Samples\\\\Tutorial41.xlsx.\")\n",
    "    workbook.easy_WriteXLSXFile(\"/home/qmis/Jaimon/Jaimon/28282.xlsx\")\n",
    "\n",
    "    # Confirm conversion of XML Spreadsheet to Excel\n",
    "    sError = workbook.easy_getError()\n",
    "\n",
    "    if sError == \"\":\n",
    "        print(\"\\nFile successfully created.\\n\")\n",
    "    else:\n",
    "            print(\"\\nError encountered: \" + sError + \"\\n\")\n",
    "else:\n",
    "    print(\"\\nError reading file C:\\\\Samples\\\\Tutorial32.xml \\n\" + workbook.easy_getError())\n",
    "\t\t\n",
    "# Dispose memory\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py4j.java_gateway\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/commands/install.py\", line 353, in run\n",
      "    wb.build(autobuilding=True)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/wheel.py\", line 749, in build\n",
      "    self.requirement_set.prepare_files(self.finder)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_set.py\", line 380, in prepare_files\n",
      "    ignore_dependencies=self.ignore_dependencies))\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_set.py\", line 554, in _prepare_file\n",
      "    require_hashes\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_install.py\", line 278, in populate_link\n",
      "    self.link = finder.find_requirement(self, upgrade)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 465, in find_requirement\n",
      "    all_candidates = self.find_all_candidates(req.name)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 423, in find_all_candidates\n",
      "    for page in self._get_pages(url_locations, project_name):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 568, in _get_pages\n",
      "    page = self._get_page(location)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 683, in _get_page\n",
      "    return HTMLPage.get_page(link, session=self.session)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 795, in get_page\n",
      "    resp.raise_for_status()\n",
      "  File \"/usr/share/python-wheels/requests-2.18.4-py2.py3-none-any.whl/requests/models.py\", line 935, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://pypi.org/simple/py4j-java-gateway/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install py4j.java_gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jtypes.py4j\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/67/9e83b47fb681b7e3343c5a3760b3fd9fa52db67c287ffc2dfd12880ac67f/jtypes.py4j-0.10.8a1.zip (646kB)\n",
      "\u001b[K    100% |████████████████████████████████| 655kB 175kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=39.2.0 (from jtypes.py4j)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/95/f657b6e17f00c3f35b5f68b10e46c3a43af353d8856bd57bfcfb1dbb3e92/setuptools-47.1.1-py3-none-any.whl (583kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 273kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting jtypes.jni (from jtypes.py4j)\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/commands/install.py\", line 353, in run\n",
      "    wb.build(autobuilding=True)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/wheel.py\", line 749, in build\n",
      "    self.requirement_set.prepare_files(self.finder)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_set.py\", line 380, in prepare_files\n",
      "    ignore_dependencies=self.ignore_dependencies))\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_set.py\", line 554, in _prepare_file\n",
      "    require_hashes\n",
      "  File \"/usr/lib/python3/dist-packages/pip/req/req_install.py\", line 278, in populate_link\n",
      "    self.link = finder.find_requirement(self, upgrade)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 465, in find_requirement\n",
      "    all_candidates = self.find_all_candidates(req.name)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 423, in find_all_candidates\n",
      "    for page in self._get_pages(url_locations, project_name):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 568, in _get_pages\n",
      "    page = self._get_page(location)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 683, in _get_page\n",
      "    return HTMLPage.get_page(link, session=self.session)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/index.py\", line 795, in get_page\n",
      "    resp.raise_for_status()\n",
      "  File \"/usr/share/python-wheels/requests-2.18.4-py2.py3-none-any.whl/requests/models.py\", line 935, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://pypi.org/simple/jtypes-jni/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jtypes.py4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ajalacomfort.com/python-4-beginners-xml-to-excel-within-a-minute/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "text\n",
      "text\n",
      "text\n",
      "[[' '], [None], ['3'], [None]]\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "#XML TO EXCEL FILE\n",
    "import xml.etree.ElementTree as ET\n",
    "from openpyxl import Workbook\n",
    "import os \n",
    "\n",
    "def readFile(filename):\n",
    "\t'''\n",
    "\t\tChecks if file exists, parses the file and extracts the needed data\n",
    "\t\treturns a 2 dimensional list without \"header\"\n",
    "\t'''\n",
    "\tif not os.path.exists(filename): return\n",
    "\ttree = ET.parse(filename)\n",
    "\troot = tree.getroot()\n",
    "\t#you may need to adjust the keys based on your file structure\n",
    "\t#dict_keys = [\"id\",\"first_name\",\"last_name\",\"email\",\"gender\",\"ip_address\" ] #all keys to be extracted from xml\n",
    "\tdict_keys = [\"text\" ] #all keys to be extracted from xml\n",
    "\tmdlist = []\n",
    "\tfor child in root:\n",
    "\t\ttemp = []\n",
    "\t\tfor key in dict_keys:\n",
    "\t\t\tprint(key)\n",
    "\t\t\ttemp.append(child.find(key).text)\n",
    "\t\tmdlist.append(temp)\n",
    "\treturn mdlist\n",
    "\n",
    "def to_Excel(mdlist):\n",
    "\t'''\n",
    "\t\tGenerates excel file with given data\n",
    "\t\tmdlist: 2 Dimenusional list containing data\n",
    "\t'''\n",
    "\tprint(mdlist)\n",
    "\twb = Workbook()\n",
    "\tws = wb.active\n",
    "\tfor i,row in enumerate(mdlist):\n",
    "\t\tfor j,value in enumerate(row):\n",
    "\t\t\tws.cell(row=i+1, column=j+1).value = value\n",
    "\tnewfilename = os.path.abspath(\"./xml_to_excel.xlsx\")\n",
    "\twb.save(newfilename)\n",
    "\tprint(\"complete\")\n",
    "\treturn\n",
    "\n",
    "result = readFile(\"/home/qmis/Jaimon/Jaimon/28282.pdf.xml\")\n",
    "if result:\n",
    "\tto_Excel(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a table from the web\n",
    "\n",
    "[stackoverflow Link!](https://stackoverflow.com/questions/59460867/downloading-a-table-from-the-web)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use pandas to ```read_html()``` and store into ```dataframe``` and then `append` to each page traverse.\n",
    "\n",
    "You need to install pandas using pip\n",
    "\n",
    "---\n",
    "> pip install pandas\n",
    "\n",
    "Use infinite loop and traverse the page until next button available else break infinite loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://dataunodc.un.org/GSH_app\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#Switch the iframe in order to access the link\n",
    "WebDriverWait(driver,15).until(EC.frame_to_be_available_and_switch_to_it((By.XPATH,\"//iframe[@src='https://unodc.shinyapps.io/GSH_App/']\")))\n",
    "#Click on National Data link\n",
    "WebDriverWait(driver,5).until(EC.element_to_be_clickable((By.XPATH,'//ul[@class=\"nav navbar-nav\"]//a[text()=\"National Data\"]'))).click()\n",
    "\n",
    "#Get all checkbox which are not selected.\n",
    "allchekbox=WebDriverWait(driver,10).until(EC.visibility_of_all_elements_located((By.XPATH,\"//input[@name='YearVar' and not(@checked='checked')]\")))\n",
    "\n",
    "for item in allchekbox:\n",
    "    item.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"table.display.dataTable.no-footer\")))\n",
    "time.sleep(2)\n",
    "html = driver.page_source\n",
    "df=pd.read_html(str(html))[0]\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "      WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"//a[@class='paginate_button next']\"))).click()\n",
    "      time.sleep(1) #slowdown for loop to load data.\n",
    "      html = driver.page_source\n",
    "      df1 = pd.read_html(str(html))[0]\n",
    "      #append data into dataframe\n",
    "      df=df.append(df1,ignore_index=True)\n",
    "\n",
    "    except:\n",
    "      break\n",
    "\n",
    "#load the data into csv file to verify all data\n",
    "df.to_csv(\"testdata.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapshot of CSV file after loaded.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/b6G5N.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Here is a good table scraper if you can get the link of the data, you just have to pass in which table to scrap:\n",
    "\n",
    "This table scrapper will read any table on a website, as long as you set whichtable, as some sites have more than one table\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContent(link, filename, whichtable=0):\n",
    "    result1 = requests.get(link)\n",
    "    src1 = result1.content\n",
    "    soup = BeautifulSoup(src1,'lxml')\n",
    "    table = soup.find_all('table')[whichtable]\n",
    "    with open(filename,'w',newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for tr in table('tr'):\n",
    "            row = [t.get_text(strip=True)for t in tr(['td','th'])]\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "getContent('https://teams.technion.ac.il/residency-placements/', 'what.csv', whichtable=0)\n",
    "df2= pd.read_csv('what.csv')\n",
    "or\n",
    "getContent('https://en.wikipedia.org/wiki/List_of_highest-grossing_films', 'what.csv', whichtable=0)\n",
    "\n",
    "\n",
    "You can see it's a very good table scrapper, and you should be able to use it on your site if you can get to the page with the actual table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
